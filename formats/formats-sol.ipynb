{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data formats solutions\n",
    "\n",
    "## [Download exercises zip](../_static/generated/formats.zip)\n",
    "\n",
    "[Browse files online](https://github.com/DavidLeoni/sciprog-ds/tree/master/formats)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial we will see how to load and write tabular data such as CSV, and we will mention tree-like data such as JSON files. We will also spend a couple of words about  opendata catalogs and licenses (creative commons).\n",
    "\n",
    "Graph formats will be discussed [in a separate notebook](https://en.softpython.org/graph-formats/graph-formats-sol.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do\n",
    "\n",
    "- unzip exercises in a folder, you should get something like this: \n",
    "\n",
    "```\n",
    "-jupman.py\n",
    "-formats     \n",
    "     formats.ipynb     \n",
    "     formats-sol.ipynb\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: to correctly visualize the notebook, it MUST be in an unzipped folder !\n",
    "</div>\n",
    "\n",
    "- open Jupyter Notebook from that folder. Two things should open, first a console and then browser. The browser should show a file list: navigate the list and open the notebook `formats/formats.ipynb`\n",
    "- Go on reading that notebook, and follow instuctions inside.\n",
    "\n",
    "\n",
    "Shortcut keys:\n",
    "\n",
    "- to execute Python code inside a Jupyter cell, press `Control + Enter`\n",
    "- to execute Python code inside a Jupyter cell AND select next cell, press `Shift + Enter`\n",
    "- to execute Python code inside a Jupyter cell AND a create a new cell aftwerwards, press `Alt + Enter`\n",
    "- If the notebooks look stuck, try to select `Kernel -> Restart`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fC_te77v5bPE"
   },
   "source": [
    "## 1. line files\n",
    "\n",
    "Line files are typically text files which contain information grouped by lines. An example using historical characters might be like the following:\n",
    "\n",
    "```\n",
    "Leonardo\n",
    "da Vinci\n",
    "Sandro\n",
    "Botticelli\n",
    "Niccolò \n",
    "Macchiavelli\n",
    "```\n",
    "We can immediately see a regularity: first two lines contain data of Leonardo da Vinci, second one the name and then the surname. Successive lines instead have data of Sandro Botticelli, with again first the name and then the surname and so on.\n",
    "\n",
    "We might want to do a program that reads the lines and prints on the terminal names and surnames like the following:\n",
    "\n",
    "```\n",
    "Leonardo da Vinci \n",
    "Sandro Botticelli\n",
    "Niccolò Macchiavelli\n",
    "```\n",
    "\n",
    "To start having an approximation of the final result, we can open the file, read only the first line and print it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "-XsMLCyU5bPH",
    "outputId": "824ecd67-35e8-4b79-bde5-ddf7f70334f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0eSCHzw5bPZ"
   },
   "source": [
    "What happened? Let's examing first rows:\n",
    "\n",
    "\n",
    "\n",
    "### open command\n",
    "\n",
    "The command\n",
    "\n",
    "```python\n",
    "open('people-simple.txt', encoding='utf-8')\n",
    "```\n",
    "\n",
    "allows us to open the text file by telling PYthon the file path `'people-simple.txt'` and the encoding in which it was written (`encoding='utf-8'`). \n",
    "\n",
    "### The encoding\n",
    "\n",
    "The encoding dependes on the operating system and on the editor used to write the file. When we open a file, Python is not capable to divine the encoding, and if we do not specify anything Python might open the file assuming an encoding different from the original - in other words, if we omit the encoding (or we put a wrong one) we might end up seeing weird characters (like little squares instead of accented letters).\n",
    "\n",
    "In general, when you open a file, try first to specify the encoding `utf-8` which is the most common one. If it doesn't work try others, for example for files written in south Europe with Windows you might check `encoding='latin-1'`. If you open a file written elsewhere, you might need other encodings. For more in-depth information, you can read [Dive into Python - Chapter 4 - Strings](https://diveintopython3.problemsolving.io/strings.html), and [Dive into Python - Chapter 11 - File](https://diveintopython3.problemsolving.io/files.html), **both of which are extremely recommended readings**.\n",
    "\n",
    "\n",
    "### with block\n",
    "\n",
    "The `with` defines a block with instructions inside:\n",
    "\n",
    "```python\n",
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    print(line)\n",
    "```\n",
    "\n",
    "We used the `with` to tell PYthon that in any case, even if errors occur, we want that after having used the file, that is after having executed the instructions inside the internal block (the `line=f.readline()` and `print(line)`) Python must automatically close the file. Properly closing a file avoids to waste memory resources and creating hard to find paranormal errors. If you want to avoid hunting for never closed zombie files, always remember to open all files in `with` blocks! Furthermore, at the end of the row in the part `as f:` we assigned the file to a variable hereby called `f`, but we could have used any other name we liked.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: To indent the code, ALWAYS use sequences of four white spaces. Sequences of 2 spaces. Sequences of only 2 spaces even if allowed are not recommended.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: Depending on the editor you use, by pressing TAB you might get a sequence o f white spaces like it happens in Jupyter (4 spaces which is the recommended length), or a special tabulation character (to avoid)! As much as this annoying this distinction might appear, remember it because it might generate very hard to find errors.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: In the commands to create blocks such as `with`, always remember to put the character of colon `:` at the end of the line !\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "en84Abg_5bPb"
   },
   "source": [
    "\n",
    "The command\n",
    "\n",
    "```\n",
    "    line=f.readline()\n",
    "```\n",
    "puts in the variable `line` the entire line, like a string. Warning: the string will contain at the end the special character of line return !\n",
    "\n",
    "You might wonder where that `readline` comes from. Like everything in Python, our variable `f` which represents the file we just opened is an object, and like any object, depending on its type, it has particular methods we can use on it. In this case the method is `readline`. \n",
    "\n",
    "The following command prints the string content:\n",
    "\n",
    "```python\n",
    "    print(line) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzyIGFfP5bPd"
   },
   "source": [
    "**✪ 1.1 EXERCISE**: Try to rewrite here the block we've just seen, and execute the cell by pressing Control-Enter. Rewrite the code with the fingers, not with copy-paste ! Pay attention to correct indentation with spaces in the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z26Xnnfm5bPg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write here\n",
    "\n",
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zsZD7-N5bPo"
   },
   "source": [
    "**✪ 1.2 EXERCISE**: you might wondering what exactly is that `f`, and what exatly the method `readlines` should be doing. When you find yourself in these situations, you might help yourself with functions `type` and `help`. This time, directly copy paste the same code here, but insert inside `with` block the commands:\n",
    "\n",
    "* `print(type(f))`\n",
    "* `print(help(f))`\n",
    "* `print(help(f.readline))`      # Attention: remember the f. before the readline !!\n",
    "\n",
    "Every time you add something, try to execute with Control+Enter and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "B5vALRz55bPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n",
      "Help on built-in function readline:\n",
      "\n",
      "readline(size=-1, /) method of _io.TextIOWrapper instance\n",
      "    Read until newline or EOF.\n",
      "    \n",
      "    Returns an empty string if EOF is hit immediately.\n",
      "\n",
      "None\n",
      "Help on TextIOWrapper object:\n",
      "\n",
      "class TextIOWrapper(_TextIOBase)\n",
      " |  Character and line based layer over a BufferedIOBase object, buffer.\n",
      " |  \n",
      " |  encoding gives the name of the encoding that the stream will be\n",
      " |  decoded or encoded with. It defaults to locale.getpreferredencoding(False).\n",
      " |  \n",
      " |  errors determines the strictness of encoding and decoding (see\n",
      " |  help(codecs.Codec) or the documentation for codecs.register) and\n",
      " |  defaults to \"strict\".\n",
      " |  \n",
      " |  newline controls how line endings are handled. It can be None, '',\n",
      " |  '\\n', '\\r', and '\\r\\n'.  It works as follows:\n",
      " |  \n",
      " |  * On input, if newline is None, universal newlines mode is\n",
      " |    enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      " |    these are translated into '\\n' before being returned to the\n",
      " |    caller. If it is '', universal newline mode is enabled, but line\n",
      " |    endings are returned to the caller untranslated. If it has any of\n",
      " |    the other legal values, input lines are only terminated by the given\n",
      " |    string, and the line ending is returned to the caller untranslated.\n",
      " |  \n",
      " |  * On output, if newline is None, any '\\n' characters written are\n",
      " |    translated to the system default line separator, os.linesep. If\n",
      " |    newline is '' or '\\n', no translation takes place. If newline is any\n",
      " |    of the other legal values, any '\\n' characters written are translated\n",
      " |    to the given string.\n",
      " |  \n",
      " |  If line_buffering is True, a call to flush is implied when a call to\n",
      " |  write contains a newline character.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextIOWrapper\n",
      " |      _TextIOBase\n",
      " |      _IOBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  close(self, /)\n",
      " |      Flush and close the IO object.\n",
      " |      \n",
      " |      This method has no effect if the file is already closed.\n",
      " |  \n",
      " |  detach(self, /)\n",
      " |      Separate the underlying buffer from the TextIOBase and return it.\n",
      " |      \n",
      " |      After the underlying buffer has been detached, the TextIO is in an\n",
      " |      unusable state.\n",
      " |  \n",
      " |  fileno(self, /)\n",
      " |      Returns underlying file descriptor if one exists.\n",
      " |      \n",
      " |      OSError is raised if the IO object does not use a file descriptor.\n",
      " |  \n",
      " |  flush(self, /)\n",
      " |      Flush write buffers, if applicable.\n",
      " |      \n",
      " |      This is not implemented for read-only and non-blocking streams.\n",
      " |  \n",
      " |  isatty(self, /)\n",
      " |      Return whether this is an 'interactive' stream.\n",
      " |      \n",
      " |      Return False if it can't be determined.\n",
      " |  \n",
      " |  read(self, size=-1, /)\n",
      " |      Read at most n characters from stream.\n",
      " |      \n",
      " |      Read from underlying buffer until we have n characters or we hit EOF.\n",
      " |      If n is negative or omitted, read until EOF.\n",
      " |  \n",
      " |  readable(self, /)\n",
      " |      Return whether object was opened for reading.\n",
      " |      \n",
      " |      If False, read() will raise OSError.\n",
      " |  \n",
      " |  readline(self, size=-1, /)\n",
      " |      Read until newline or EOF.\n",
      " |      \n",
      " |      Returns an empty string if EOF is hit immediately.\n",
      " |  \n",
      " |  seek(self, cookie, whence=0, /)\n",
      " |      Change stream position.\n",
      " |      \n",
      " |      Change the stream position to the given byte offset. The offset is\n",
      " |      interpreted relative to the position indicated by whence.  Values\n",
      " |      for whence are:\n",
      " |      \n",
      " |      * 0 -- start of stream (the default); offset should be zero or positive\n",
      " |      * 1 -- current stream position; offset may be negative\n",
      " |      * 2 -- end of stream; offset is usually negative\n",
      " |      \n",
      " |      Return the new absolute position.\n",
      " |  \n",
      " |  seekable(self, /)\n",
      " |      Return whether object supports random access.\n",
      " |      \n",
      " |      If False, seek(), tell() and truncate() will raise OSError.\n",
      " |      This method may need to do a test seek().\n",
      " |  \n",
      " |  tell(self, /)\n",
      " |      Return current stream position.\n",
      " |  \n",
      " |  truncate(self, pos=None, /)\n",
      " |      Truncate file to size bytes.\n",
      " |      \n",
      " |      File pointer is left unchanged.  Size defaults to the current IO\n",
      " |      position as reported by tell().  Returns the new size.\n",
      " |  \n",
      " |  writable(self, /)\n",
      " |      Return whether object was opened for writing.\n",
      " |      \n",
      " |      If False, write() will raise OSError.\n",
      " |  \n",
      " |  write(self, text, /)\n",
      " |      Write string to stream.\n",
      " |      Returns the number of characters written (which is always equal to\n",
      " |      the length of the string).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  buffer\n",
      " |  \n",
      " |  closed\n",
      " |  \n",
      " |  encoding\n",
      " |      Encoding of the text stream.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  errors\n",
      " |      The error setting of the decoder or encoder.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  line_buffering\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  newlines\n",
      " |      Line endings translated so far.\n",
      " |      \n",
      " |      Only line endings translated during reading are considered.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _IOBase:\n",
      " |  \n",
      " |  __del__(...)\n",
      " |  \n",
      " |  __enter__(...)\n",
      " |  \n",
      " |  __exit__(...)\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  readlines(self, hint=-1, /)\n",
      " |      Return a list of lines from the stream.\n",
      " |      \n",
      " |      hint can be specified to control the number of lines read: no more\n",
      " |      lines will be read if the total size (in bytes/characters) of all\n",
      " |      lines so far exceeds hint.\n",
      " |  \n",
      " |  writelines(self, lines, /)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _IOBase:\n",
      " |  \n",
      " |  __dict__\n",
      "\n",
      "None\n",
      "Leonardo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write here the code (copy and paste)\n",
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    print(type(f))\n",
    "    print(help(f.readline))\n",
    "    print(help(f))\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I53T_-LV5bPx"
   },
   "source": [
    "\n",
    "First we put the content of the first line into the variable `line`, now we might put it in a variable witha  more meaningful name, like `name`. Also, we can directly read the next row into the variable `surname` and then print the concatenation of both:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "nK3hZrCq5bP0",
    "outputId": "49e2a028-ba09-4d96-be97-43a08ef3686b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo\n",
      " da Vinci\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    name=f.readline()\n",
    "    surname=f.readline()\n",
    "    print(name + ' ' + surname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UwUBQnc5bP-"
   },
   "source": [
    "**PROBLEM !** The printing puts a weird carriage return. Why is that? If you remember, first we said that `readline` reads the line content in a string adding to the end also the special newline character. To eliminate it, you can use the command `rstrip()`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "cNvkN5BD5bQB",
    "outputId": "d9dd006e-6bd9-4671-c98c-3af68cce2dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci\n"
     ]
    }
   ],
   "source": [
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    name=f.readline().rstrip()\n",
    "    surname=f.readline().rstrip()\n",
    "    print(name + ' ' + surname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XWpXow25bQM"
   },
   "source": [
    "**✪ 1.3 EXERCISE**: Again, rewrite the block above in the cell below, ed execute the cell with Control+Enter. Question: what happens if you use `strip()` instead of `rstrip()`? What about `lstrip()`? Can you deduce the meaning of `r` and `l`? If you can't manage it, try to use python command `help` by calling `help(string.rstrip)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cMnM_Ywm5bQP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci\n"
     ]
    }
   ],
   "source": [
    "# write here\n",
    "\n",
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    name=f.readline().rstrip()\n",
    "    surname=f.readline().rstrip()\n",
    "    print(name + ' ' + surname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7vruQTu5bQb"
   },
   "source": [
    "Very good, we have the first line ! Now we can read all the lines in sequence. To this end, we can use a `while` cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "dXZBiWN-5bQh",
    "outputId": "607b53ee-8c4d-48cc-dc06-c8d6c0996223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci\n",
      "Sandro Botticelli\n",
      "Niccolò Macchiavelli\n"
     ]
    }
   ],
   "source": [
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    while line != \"\":                \n",
    "        name = line.rstrip()\n",
    "        surname=f.readline().rstrip()\n",
    "        print(name + ' ' + surname)\n",
    "        line=f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE**: In Python there are [shorter ways](https://thispointer.com/5-different-ways-to-read-a-file-line-by-line-in-python/) \n",
    "to read a text file line by line, we used this approach  to make explicit all passages.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs1Fthi-5bQr"
   },
   "source": [
    "What did we do? First, we added a `while` cycle in a new block\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: In new block, since it is already within the external `with`, the instructions are indented of 8 spaces and not 4! If you use the wrong spaces, bad things happen !\n",
    "\n",
    "</div>\n",
    "\n",
    "We first read a line, and two cases are possible: \n",
    "\n",
    "a. we are the end of the file (or file is empty) : in this case  `readline()` call returns an empty string\n",
    "\n",
    "b. we are not at the end of the file: the first line is put as a string inside the variable `line`. Since Python internally uses a pointer to keep track at which position we are when reading inside the file, after the read such pointer is moved at the beginning of the next line. This way the next call to `readline()` will read a line from the new position.\n",
    "\n",
    "In `while` block we tell Python to continue the cycle as long as `line` is _not_ empty. If this is the case, inside the `while` block we parse the name from the line and put it in variable `name` (removing extra newline character with `rstrip()` as we did before), then we proceed reading the next line and parse the result inside the `surname` variable. Finally, we read again a line into the `line` variable so it will be ready for the next round of name extraction. If line is empty the cycle will terminate:\n",
    "\n",
    "\n",
    "```python\n",
    "while line != \"\":                   # enter cycle if line contains characters\n",
    "    name = line.rstrip()            # parses the name\n",
    "    surname=f.readline().rstrip()   # reads next line and parses surname\n",
    "    print(name + ' ' + surname)     \n",
    "    line=f.readline()               # read next line\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2RxmnlK5bQu"
   },
   "source": [
    "**✪ 1.4 EXERCISE**: As before, rewrite in the cell below the code with the `while`, paying attention to the indentation (for the external `with` line use copy-and-paste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rElpI-gY5bQw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci\n",
      "Sandro Botticelli\n",
      "Niccolò Macchiavelli\n"
     ]
    }
   ],
   "source": [
    "# write here the code of internal while\n",
    "\n",
    "with open('people-simple.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    while line != \"\":                \n",
    "        name = line.rstrip()\n",
    "        surname=f.readline().rstrip()\n",
    "        print(name + ' ' + surname)\n",
    "        line=f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6pP7nWFc5bQ4"
   },
   "source": [
    "### people-complex line file: \n",
    "\n",
    "Look at the file `people-complex.txt`:\n",
    "\n",
    "```\n",
    "name: Leonardo\n",
    "surname: da Vinci\n",
    "birthdate: 1452-04-15\n",
    "name: Sandro\n",
    "surname: Botticelli\n",
    "birthdate: 1445-03-01\n",
    "name: Niccolò \n",
    "surname: Macchiavelli\n",
    "birthdate: 1469-05-03\n",
    "```\n",
    "Supposing to read the file to print this output, how would you do it? \n",
    "\n",
    "```\n",
    "Leonardo da Vinci, 1452-04-15\n",
    "Sandro Botticelli, 1445-03-01\n",
    "Niccolò Macchiavelli, 1469-05-03\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c76qOu-25bQ7"
   },
   "source": [
    "\n",
    "**Hint 1**: to obtain the string `'abcde'`, the substring  `'cde'`, which starts at index 2, you can ue the operator square brackets, using the index followed by colon `:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "wbGZhl2w5bQ-",
    "outputId": "d42be766-a32c-44c6-c44f-b29b34817cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cde'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abcde'\n",
    "x[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "Nr3E0n-d5bRI",
    "outputId": "33bdbff3-051a-4c6f-86b0-209fa7706cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlDQzVWG5bRS"
   },
   "source": [
    "**Hint 2**: To know the length of a string, use the function `len`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "G5-AXund5bRT",
    "outputId": "2bc3c444-04d0-4053-d3c0-60fe33ed6099"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('abcde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVA0FPut5bRe"
   },
   "source": [
    "**✪ 1.5 EXERCISE**: Write here the solution of the exercise 'People complex':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XlS5VSI05bRg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci, 1452-04-15\n",
      "Sandro Botticelli, 1445-03-01\n",
      "Niccolò Macchiavelli, 1469-05-03\n"
     ]
    }
   ],
   "source": [
    "# write here  \n",
    "        \n",
    "with open('people-complex.txt', encoding='utf-8') as f:\n",
    "    line=f.readline()\n",
    "    while line != \"\":                \n",
    "        name = line.rstrip()[len(\"name: \"):]\n",
    "        surname= f.readline().rstrip()[len(\"surname: \"):]\n",
    "        born = f.readline().rstrip()[len(\"birthdate: \"):]\n",
    "        print(name + ' ' + surname + ', ' + born)\n",
    "        line=f.readline()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_F0X5jm5bRo"
   },
   "source": [
    "### Exercise - line file immersione-in-python-toc\n",
    "\n",
    "✪✪✪ This exercise is more challenging, if you are a beginner you might skip it and go on to CSVs\n",
    "\n",
    "The book Dive into Python is nice and for the italian version there is a PDF, which has a problem though: if you try to print it, you will discover that the index is missing. Without despairing, we found a program to extract titles in a file as follows, but you will discover it is not exactly nice to see. Since we are Python ninjas, we decided to transform raw titles in a [real table of contents](http://softpython.readthedocs.io/it/latest/_static/toc-immersione-in-python-3.txt). Sure enough there are smarter ways to do this, like loading the pdf in Python with an appropriate module for pdfs, still this makes for an interesting exercise.\n",
    "\n",
    "You are given the file `immersione-in-python-toc.txt`:\n",
    "\n",
    "```\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Il vostro primo programma Python\n",
    "BookmarkLevel: 1\n",
    "BookmarkPageNumber: 38\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Immersione!\n",
    "BookmarkLevel: 2\n",
    "BookmarkPageNumber: 38\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Dichiarare funzioni\n",
    "BookmarkLevel: 2\n",
    "BookmarkPageNumber: 41\n",
    "BookmarkBeginint\n",
    "BookmarkTitle: Argomenti opzionali e con nome\n",
    "BookmarkLevel: 3\n",
    "BookmarkPageNumber: 42\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Scrivere codice leggibile\n",
    "BookmarkLevel: 2\n",
    "BookmarkPageNumber: 44\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Stringhe di documentazione\n",
    "BookmarkLevel: 3\n",
    "BookmarkPageNumber: 44\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Il percorso di ricerca di import\n",
    "BookmarkLevel: 2\n",
    "BookmarkPageNumber: 46\n",
    "BookmarkBegin\n",
    "BookmarkTitle: Ogni cosa &#232; un oggetto\n",
    "BookmarkLevel: 2\n",
    "BookmarkPageNumber: 47\n",
    "```\n",
    "\n",
    "Write a python program to print the following output:\n",
    "\n",
    "```\n",
    "   Il vostro primo programma Python  38\n",
    "      Immersione!  38\n",
    "      Dichiarare funzioni  41\n",
    "         Argomenti opzionali e con nome  42\n",
    "      Scrivere codice leggibile  44\n",
    "         Stringhe di documentazione  44\n",
    "      Il percorso di ricerca di import  46\n",
    "      Ogni cosa è un oggetto  47\n",
    "```\n",
    "\n",
    "For this exercise, you will need to insert in the output artificial spaces, in a qunatity determined by the rows `BookmarkLevel`\n",
    "\n",
    "\n",
    "**QUESTION**: what's that weird value `&#232;` at the end of the original file? Should we report it in the output?\n",
    "\n",
    "**HINT 1**: To convert a string into an integer number, use the function `int`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XWlxnhpX5bRy"
   },
   "outputs": [],
   "source": [
    "x = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "GdJd09mZ5bR_",
    "outputId": "dc19c940-e1af-4c84-aa60-012cfb985133"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "nETKnztF5bSF",
    "outputId": "118522fe-186c-452e-9218-223508605154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwfLN6lv5bSQ"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning**: `int(x)` returns a value, and never modifies the argument `x`!  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w06zsF1a5bSS"
   },
   "source": [
    "**HINT 2**: To substitute a substring in a string, you can use the method `.replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "sGPUddlf5bST",
    "outputId": "4af45183-e44d-4fad-a1ba-16c6722c62ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abHELLOe'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abcde'\n",
    "x.replace('cd', 'HELLO' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7OBEbHya5bSd"
   },
   "source": [
    "**HINT 3**: while there is only one sequence to substitute, `replace` is fine, but if we had a milion of horrible sequences like `&gt;`, `&#62;`, `&x3e;`, what should we do? As good data cleaners, we recognize these are [HTML escape sequences](https://corsidia.com/materia/web-design/caratterispecialihtml), so we could use  methods specific to sequences like [html.escape](https://docs.python.org/3/library/html.html#html.unescape). TRy it instead of `replace` and check if it works!\n",
    "\n",
    "\n",
    "NOTE: Before using `html.unescape`, import the module `html` with the command: \n",
    "\n",
    "```python\n",
    "import html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2scPeP15bSe"
   },
   "source": [
    "**HINT 4**: To write _n_ copies of a character, use `*` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "0mOU41SC5bSf",
    "outputId": "74391ce6-fef1-4d9e-a630-804af033f3fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"b\" * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "NK5lFuks5bSm",
    "outputId": "56bed93f-878f-4d92-88fc-2afef788218c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbbbbbb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"b\" * 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58yyJFaf5bSu"
   },
   "source": [
    "**IMPLEMENTATION**: Write here the solution for the line file `immersione-in-python-toc.txt`, and try execute it by pressing Control + Enter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ndZarkM45bSv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Il vostro primo programma Python  38\n",
      "      Immersione!  38\n",
      "      Dichiarare funzioni  41\n",
      "         Argomenti opzionali e con nome  42\n",
      "      Scrivere codice leggibile  44\n",
      "         Stringhe di documentazione  44\n",
      "      Il percorso di ricerca di import  46\n",
      "      Ogni cosa è un oggetto  47\n"
     ]
    }
   ],
   "source": [
    "# write here \n",
    "\n",
    "import html\n",
    "\n",
    "with open(\"immersione-in-python-toc.txt\", encoding='utf-8') as f:\n",
    "\n",
    "    line=f.readline()  \n",
    "    while line != \"\":\n",
    "        line = f.readline().strip()\n",
    "        title = html.unescape(line[len(\"BookmarkTitle: \"):])\n",
    "        line=f.readline().strip()\n",
    "        level = int(line[len(\"BookmarkLevel: \"):])\n",
    "        line=f.readline().strip()\n",
    "        page = line[len(\"BookmarkPageNumber: \"):]\n",
    "        print((\"   \" * level) + title + \"  \" + page)\n",
    "        line=f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47Jg7yaZ5bSy"
   },
   "source": [
    "## 2. CSV files\n",
    "\n",
    "There can be various formats for tabular data, among which you surely know Excel  (`.xls` or `.xslx`). Unfortunately, if you want to programmatically process data, you should better avoid them and prefer if possible the CSV format, literally 'Comma Separated Value'. Why? Excel format is very complex and may hide several things which have nothing to do with the raw data:\n",
    "\n",
    "- formatting (bold fonts, colors ...)\n",
    "- merged cells\n",
    "- formulas\n",
    "- multiple tabs\n",
    "- macros\n",
    "\n",
    "Correctly parsing complex files may become a nightmare. Instead, CSVs are far simpler, so much so you can even open them witha simple text editor.\n",
    "\n",
    "We will try to open some CSV, taking into consideration the possible problems we might get. CSVs are not necessarily the perfect solution for everything, but they offer more control over reading and typically if there are conversion problems is because we made a mistake, and not because the reader module decided on its own to exchange days with months in dates.\n",
    "\n",
    "### Why parsing a CSV ?\n",
    "\n",
    "To load and process CSVs there exist many powerful and intuitive modules such as Pandas in Python or R dataframes. Yet, in this notebook we will load CSVs using the most simple method possible, that is reading row by row, mimicking the method already seen in the previous part of the tutorial. Don't think this method is primitive or stupid, according to the situation it may save the day. How? Some files may potentially occupy huge amounts of memory, and in moder laptops as of 2019 we only have 4 gigabytes of RAM, the memory where Python stores variables. Given this, Python base functions to read files try their best to avoid loading everything in RAM. Tyipcally a file is read sequentially one piece at a time, putting in RAM only one row at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 2.1**: if we want to know if a given file of 1000 terabytes contains only 3 million rows in which the word 'ciao' is present, are we obliged to put in RAM _all_ of the rows ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: no, it is sufficient to keep in memory one row at a time, and hold the count in another variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 2.2**: What if we wanted to take a 100 terabyte file and create another one by appending to each row of the first one the word 'ciao'? Should we put in RAM at the same time all the rows of the first file ? What about the rows of second one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**:  No, it is enough to keep in RAM one row at a time, which is first read from the first file and then written right away in the second file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a CSV\n",
    "\n",
    "We will start with artifical example CSV. Let's look at [example-1.csv](example-1.csv) which you can find in the same folder as this Jupyter notebook. It contains animals with their expected lifespan:\n",
    "\n",
    "```\n",
    "animal, lifespan\n",
    "dog, 12\n",
    "cat, 14\n",
    "pelican, 30\n",
    "squirrel, 6\n",
    "eagle, 25\n",
    "```\n",
    "\n",
    "We notice right away that the CSV is more structured than files we've seen in the previous section\n",
    "\n",
    "* in the first line there are column names, separated with commas: `animal, lifespan`\n",
    "* fields in successive rows are also separated by commas `,`: `dog, 12`\n",
    "\n",
    "Let's try now to import this file in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just read a row !\n",
      "['animal', ' lifespan']\n",
      "\n",
      "We just read a row !\n",
      "['dog', '12']\n",
      "\n",
      "We just read a row !\n",
      "['cat', '14']\n",
      "\n",
      "We just read a row !\n",
      "['pelican', '30']\n",
      "\n",
      "We just read a row !\n",
      "['squirrel', '6']\n",
      "\n",
      "We just read a row !\n",
      "['eagle', '25']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:\n",
    "    \n",
    "    # we create an object 'my_reader' which will take rows from the file\n",
    "    my_reader = csv.reader(f, delimiter=',') \n",
    "    \n",
    "    # 'my_reader' is an object considered 'iterable', that is, \n",
    "    # if used in a 'for' will produce a sequnce of rows from csv\n",
    "    # NOTE: here every file row is converted into a list of Python strings !\n",
    "    \n",
    "    for row in my_reader:\n",
    "        print('We just read a row !')        \n",
    "        print(row)  # prints variable 'row', which is a list of strings\n",
    "        print('')   # prints an empty string, to separate in vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediatly notice from output that example file is being printed, but there are square parrenthesis ( `[]` ). What do they mean? Those we printed are _lists of strings_\n",
    "\n",
    "Let's analyze what we did:\n",
    "\n",
    "```python\n",
    "import csv\n",
    "```\n",
    "Python natively has a module to deal with csv files, which has the intuitive `csv` name. With this instruction, we just loaded the module.\n",
    "\n",
    "What happens next? As already did for files with lines before, we open the file in a `with` block:\n",
    "\n",
    "```python\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:\n",
    "    my_reader = csv.reader(f, delimiter=',')\n",
    "    for row in my_reader:\n",
    "        print(row)\n",
    "```\n",
    "For now ignore the `newline=''` and notice how first we specificed the encoding\n",
    "\n",
    "Once the file is open, in the row \n",
    "\n",
    "```python\n",
    "    my_reader = csv.reader(f, delimiter=',')\n",
    "```\n",
    "\n",
    "we ask to `csv` module to create a reader object  called `my_reader` for our file, telling Python that comma is the delimiter for fields.\n",
    "\n",
    "**NOTE:** `my_reader` is the name of the variable we are creating, it could be any name.\n",
    "\n",
    "This reader object can be exploited as a sort of generator of rows by using a `for` cycle:\n",
    "\n",
    "```\n",
    "    for row in my_reader:\n",
    "        print(row)\n",
    "```\n",
    "\n",
    "In `for` cycle we employ `lettore` to iterate in the reading of the file, producing at each iteration a row we call `row` (but it could be any name we like). At each iteration, the variable `row` gets printed.\n",
    "\n",
    "If you look closely the prints of first lists, you will see that each time to each row is assigned only one Python list. The list contains as many elements as the number of fields in the CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪ EXERCISE 2.3**: Rewrite in the cell below the instructions to read and print the CSV, paying attention to indentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just read a row !\n",
      "['animal', ' lifespan']\n",
      "\n",
      "We just read a row !\n",
      "['dog', '12']\n",
      "\n",
      "We just read a row !\n",
      "['cat', '14']\n",
      "\n",
      "We just read a row !\n",
      "['pelican', '30']\n",
      "\n",
      "We just read a row !\n",
      "['squirrel', '6']\n",
      "\n",
      "We just read a row !\n",
      "['eagle', '25']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:\n",
    "    \n",
    "    # we create an object 'my_reader' which will take rows from the file\n",
    "    my_reader = csv.reader(f, delimiter=',') \n",
    "    \n",
    "    # 'my_reader' is an object considered 'iterable', that is, \n",
    "    # if used in a 'for' will produce a sequnce of rows from csv\n",
    "    # NOTE: here every file row is converted into a list of Python strings !\n",
    "    \n",
    "    for row in my_reader:\n",
    "        print(\"We just read a row !\")        \n",
    "        print(row)  # prints variable 'row', which is a list of strings\n",
    "        print('')   # prints an empty string, to separate in vertical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪✪ EXERCISE 2.4**: try to put into `big_list` a list containing all the rows extracted from the file, which will be a list of lists like so:\n",
    "\n",
    "```\n",
    "[['eagle', 'lifespan'],\n",
    " ['dog', '12'],\n",
    " ['cat', '14'],\n",
    " ['pelican', '30'],\n",
    " ['squirrel', '6'],\n",
    " ['eagle', '25']]\n",
    "```\n",
    "\n",
    "**HINT**: Try creating an empty list and then adding elements with `.append` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['animal', ' lifespan'], ['dog', '12'], ['cat', '14'], ['pelican', '30'], ['squirrel', '6'], ['eagle', '25']]\n"
     ]
    }
   ],
   "source": [
    "# write here\n",
    "\n",
    "\n",
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:\n",
    "    \n",
    "    # we create an object 'my_reader' which will take rows from the file\n",
    "    my_reader = csv.reader(f, delimiter=',') \n",
    "    \n",
    "    # 'my_reader' is an object considered 'iterable', that is, \n",
    "    # if used in a 'for' will produce a sequnce of rows from csv\n",
    "    # NOTE: here every file row is converted into a list of Python strings !\n",
    "    \n",
    "    big_list = []\n",
    "    for row in my_reader:\n",
    "        big_list.append(row)\n",
    "    print(big_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪✪ EXERCISE 2.5**: You may have noticed that numbers in lists are represented as strings like `'12'` (note apeces), instead that like Python integer numbers (represented without apeces), `12`:\n",
    "\n",
    "\n",
    "```\n",
    "We just read a row!\n",
    "['dog', '12']\n",
    "```\n",
    "\n",
    "So, by reading the file and using normal for cycles, try to create a new variable `big_list` like this, which\n",
    "\n",
    "\n",
    "- has only data, the row with the header is not present\n",
    "- numbers are represented as proper integers\n",
    "\n",
    "```\n",
    "[['dog', 12], \n",
    " ['cat', 14], \n",
    " ['pelican', 30], \n",
    " ['squirrel', 6], \n",
    " ['eagle', 25]]\n",
    "```\n",
    "\n",
    "**HINT 1**: to jump a row you can use the instruction `next(my_reader)`\n",
    "\n",
    "**HINT 2**: to convert a string into an integer, you can use for example. `int('25')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dog', 12], ['cat', 14], ['pelican', 30], ['squirrel', 6], ['eagle', 25]]\n"
     ]
    }
   ],
   "source": [
    "# write here\n",
    "\n",
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.reader(f, delimiter=',')     \n",
    "    big_list = []\n",
    "    next(my_reader)\n",
    "    for row in my_reader:\n",
    "        big_list.append([row[0], int(row[1])])\n",
    "    print(big_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's a reader ?\n",
    "\n",
    "We said that `my_reader` generates a sequence of rows, and it is _iterable_. In `for` cycle, at every cycle we ask to read a new line, which is put into variable `row`. We might then ask ourselves, what happens if we directly  print `my_reader`, without any `for`? Will we see a nice list or something else? Let's try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x7fc08c2d2978>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.reader(f, delimiter=',')     \n",
    "    print(my_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is quite disappointing\n",
    "\n",
    "**✪ EXERCISE 2.6**: you probably found yourself in the same situation when trying to print a sequence generated by a call to `range(5)`: instead of the actual sequence you get a `range` object. If you want to convert the generator to a list, what should you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['animal', ' lifespan'], ['dog', '12'], ['cat', '14'], ['pelican', '30'], ['squirrel', '6'], ['eagle', '25']]\n"
     ]
    }
   ],
   "source": [
    "# write here\n",
    "\n",
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.reader(f, delimiter=',')     \n",
    "    print(list(my_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consuming a file\n",
    "\n",
    "Not all sequences are the same. From what you've seen so far, going through a file in Python looks a lot like iterating a list. Which is very handy, but you need to pay attention to some things. Given that files potentially might occupy terabytes, basic Python functions to load them avoid loading everything into memory and typically a file is read one piece at a time. But if the whole file is loaded into Python environment in one shot, what happens if we try to go through it twice inside the same `with` ? What happens if we try using it outside `with`? To find out look at next exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪ EXERCISE 2.7**: taking the solution to previous exercise, try to call `print(list(my_reader))` twice, in sequence. Do you get the same output in both occasions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the code\n",
    "\n",
    "#import csv\n",
    "#with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "#    my_reader = csv.reader(f, delimiter=',')     \n",
    "#    print(list(my_reader))\n",
    "#    print(list(my_reader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪ EXERCISE 2.8**: Taking the solution from previous exercise (using only one print), try down here to move the print to the left (removing any spaces). Does it still work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here\n",
    "\n",
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.reader(f, delimiter=',')         \n",
    "#print(list(my_reader))    # COMMENTED, AS IT WOULD RAISE ON ERROR OF CLOSED FILE\n",
    "                           # We can't use commands which read the file outside the with ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪✪ EXERCISE 2.9**: Now that we understood which kind of beast `my_reader` is, try to produce this result as done before, but using a _list comprehension_ instead of the `for`:\n",
    "\n",
    "```\n",
    "[['dog', 12], \n",
    " ['cat', 14], \n",
    " ['pelican', 30], \n",
    " ['squirrel', 6], \n",
    " ['eagle', 25]]\n",
    "```\n",
    "\n",
    "* If you can, try also to write the whole transformation to create `big_list` in one row, usinf the function [itertools.islice](https://docs.python.org/3/library/itertools.html#itertools.islice) to jump the header (for example `itertools.islice(['A', 'B', 'C', 'D', 'E'], 2, None)` first two elements and produces the sequence C D E F G - in our case the elements produced by `my_reader` would be rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dog', 12], ['cat', 14], ['pelican', 30], ['squirrel', 6], ['eagle', 25]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import itertools\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.reader(f, delimiter=',')     \n",
    "    # write here\n",
    "    big_list = [[row[0], int(row[1])] for row in itertools.islice(my_reader, 1, None)]\n",
    "    print(big_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪ EXERCISE 2.10**: Create a file `my-example.csv` in the same folder where this Jupyter notebook is, and copy inside the content of the file `example-1.csv`. Then add a column `description`, remembering to separate the column name from the preceding one with a comma. As column values, put into successive rows strings like `dogs walk`, `pelicans fly`, etc according to the animal, remembering to separate them from lifespan using a comma, like this:\n",
    "\n",
    "`dog,12,dogs walk`\n",
    "\n",
    "After this, copy and paste down here the Python code to load the file, putting the file name `my-example.csv`, and try to load everything, just to check everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**:\n",
    "\n",
    "```\n",
    "animal,lifespan,description\n",
    "dog,12,dogs walk\n",
    "cat,14,cats walk\n",
    "pelican,30,pelicans fly\n",
    "squirrel,6,squirrels fly\n",
    "eagle,25,eagles fly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✪ Exercise 2.11**: Not every CSV is structured in the same way, sometimes when we write csvs or import them some tweak is necessary. Let's see which problems may arise:\n",
    "\n",
    "- In the file, try to put one or two spaces before numbers, for example write down here and look what happens\n",
    "\n",
    "```\n",
    "dog, 12,dogs fly\n",
    "```\n",
    "\n",
    "**QUESTION 2.11.1**: Does the space get imported?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 2.11.2**: if we convert to integer, is the space a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**QUESTION 2.11.3** Modify only dogs description from `dogs walk` to `dogs walk, but don't fly` and try to riexecute the cell which opens the file. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Python reads one element more in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 2.11.4**: To overcome previous problem, a solution you can adopt in CSVs is to round strings containing commas with double quotes, like this: `\"dogs walk, but don't fly\"`. Does it work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading as dictionaries\n",
    "\n",
    "To read a CSV, instead of getting lists, you may more conveniently get dictionaries in the form of `OrderedDict`s\n",
    "\n",
    "See [Python documentation](https://docs.python.org/3/library/csv.html#csv.DictReader)\n",
    "\n",
    "**NOTE**: different Python versions give different dictionaries:\n",
    "\n",
    "* $<$ 3.6: `dict`\n",
    "* 3.6, 3.7: `OrderedDict`\n",
    "* $\\geq$ 3.8: `dict`\n",
    "\n",
    "Python 3.8 returned to old  `dict` because in the implementation of its dictionariesthe key order is guaranteed, so it will be consistent with the one of CSV headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal': 'dog', ' lifespan': '12'}\n",
      "{'animal': 'cat', ' lifespan': '14'}\n",
      "{'animal': 'pelican', ' lifespan': '30'}\n",
      "{'animal': 'squirrel', ' lifespan': '6'}\n",
      "{'animal': 'eagle', ' lifespan': '25'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('example-1.csv', encoding='utf-8', newline='') as f:    \n",
    "    my_reader = csv.DictReader(f, delimiter=',')   # Notice we now used DictReader\n",
    "    for d in my_reader:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily create a CSV by instantiating a `writer` object: \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**ATTENTION: BE SURE TO WRITE IN THE CORRECT FILE!**\n",
    "\n",
    "If you don't pay attention to file names, **you risk deleting data !**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# To write, REMEMBER to specify the `w` option.\n",
    "# WARNING: 'w' *completely* replaces existing files !!\n",
    "with open('written-file.csv', 'w', newline='') as csvfile_out: \n",
    "    \n",
    "    my_writer = csv.writer(csvfile_out, delimiter=',')    \n",
    "    \n",
    "    my_writer.writerow(['This', 'is', 'a header'])\n",
    "    my_writer.writerow(['some', 'example', 'data'])\n",
    "    my_writer.writerow(['some', 'other', 'example data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and writing a CSV\n",
    "\n",
    "To create a copy of an existing CSV, you may nest a `with` for writing inside another for reading:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**ATTENTION: CAREFUL NOT TO SWAP FILE NAMES!**\n",
    "\n",
    "When we read and write it's easy to make mistakes and accidentally overwrite our precious data.\n",
    "</div>\n",
    "\n",
    "**To avoid issues:**\n",
    "\n",
    "* use explicit names both for output files (es: `example-1-enriched.csv` and handles (i.e. `csvfile_out`)\n",
    "* backup data to read\n",
    "* always check before carelessly executing code you just wrote !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "    \n",
    "# To write, REMEMBER to specify the `w` option.\n",
    "# WARNING: 'w' *completely* replaces existing files !!\n",
    "# WARNING: handle here  is called *csvfile_out*\n",
    "with open('example-1-enriched.csv', 'w', encoding='utf-8', newline='') as csvfile_out: \n",
    "    my_writer = csv.writer(csvfile_out, delimiter=',')\n",
    "\n",
    "    # Notice how this 'with' is *inside* the outer one:\n",
    "    # WARNING: handle here is called *csvfile_in*\n",
    "    with open('example-1.csv', encoding='utf-8', newline='') as csvfile_in:    \n",
    "        my_reader = csv.reader(csvfile_in, delimiter=',')      \n",
    "        \n",
    "        for row in my_reader:\n",
    "            row.append('something else')\n",
    "            my_writer.writerow(row)\n",
    "            my_writer.writerow(row)\n",
    "            my_writer.writerow(row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the new file was actually created by reading it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animal', ' lifespan', 'something else']\n",
      "['animal', ' lifespan', 'something else']\n",
      "['animal', ' lifespan', 'something else']\n",
      "['dog', '12', 'something else']\n",
      "['dog', '12', 'something else']\n",
      "['dog', '12', 'something else']\n",
      "['cat', '14', 'something else']\n",
      "['cat', '14', 'something else']\n",
      "['cat', '14', 'something else']\n",
      "['pelican', '30', 'something else']\n",
      "['pelican', '30', 'something else']\n",
      "['pelican', '30', 'something else']\n",
      "['squirrel', '6', 'something else']\n",
      "['squirrel', '6', 'something else']\n",
      "['squirrel', '6', 'something else']\n",
      "['eagle', '25', 'something else']\n",
      "['eagle', '25', 'something else']\n",
      "['eagle', '25', 'something else']\n"
     ]
    }
   ],
   "source": [
    "with open('example-1-enriched.csv', encoding='utf-8', newline='') as csvfile_in:    \n",
    "    my_reader = csv.reader(csvfile_in, delimiter=',')      \n",
    "\n",
    "    for row in my_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbO-GSrX5bSz"
   },
   "source": [
    "\n",
    "### CSV Botteghe storiche \n",
    "\n",
    "Usually in open data catalogs like the popular CKAN platform (for example [dati.trentino.it](http://dati.trentino.it/), [data.gov.uk](https://data.gov.uk/), [European data portal](https://www.europeandataportal.eu/) run instances of CKAN) files are organized in _datasets_, which are collections of _resources_: each resource directly contains a file inside the catalog (typically CSV, JSON or XML) or a link to the real file located in a server belonging to the organizazion which created the data.\n",
    "\n",
    "The first dataset we wil look at will be 'Botteghe storiche del Trentino':\n",
    "\n",
    "https://dati.trentino.it/dataset/botteghe-storiche-del-trentino\n",
    "\n",
    "Here you will find some generic information about the dataset, of importance note the data provider: Provincia Autonoma di Trento and the license [Creative Commons Attribution v4.0](https://creativecommons.org/licenses/by/4.0/deed.en), which basically allows any reuse provided you cite the author.\n",
    "\n",
    "Inside the dataset page, there is a resource called 'Botteghe storiche'\n",
    "\n",
    "https://dati.trentino.it/dataset/botteghe-storiche-del-trentino/resource/43fc327e-99b4-4fb8-833c-1807b5ef1d90\n",
    "\n",
    "At the resource page, we find a link to the CSV file (you can also find it by clicking on the blue button 'Go to the resource'):\n",
    "\n",
    "http://www.commercio.provincia.tn.it/binary/pat_commercio/valorizzazione_luoghi_storici/Albo_botteghe_storiche_in_ordine_iscrizione_9_5_2019.1557403385.csv\n",
    "\n",
    "Accordingly to the browser and operating system you have, by clicking on the link above you might get different results. In our case, on browser Firefox and operating system Linux we get (here we only show first 10 rows):\n",
    "\n",
    "```\n",
    "Numero,Insegna,Indirizzo,Civico,Comune,Cap,Frazione/LocalitÃ ,Note\n",
    "1,BAZZANELLA RENATA,Via del Lagorai,30,Sover,38068,Piscine di Sover,\"generi misti, bar - ristorante\"\n",
    "2,CONFEZIONI MONTIBELLER S.R.L.,Corso Ausugum,48,Borgo Valsugana,38051,,esercizio commerciale\n",
    "3,FOTOGRAFICA TRINTINAGLIA UMBERTO S.N.C.,Largo Dordi,8,Borgo Valsugana,38051,,\"esercizio commerciale, attivitÃ  artigianale\"\n",
    "4,BAR SERAFINI DI MINATI RENZO,,24,Grigno,38055,Serafini,esercizio commerciale\n",
    "6,SEMBENINI GINO & FIGLI S.R.L.,Via S. Francesco,35,Riva del Garda,38066,,\n",
    "7,HOTEL RISTORANTE PIZZERIA â€œALLA NAVEâ€,Via Nazionale,29,Lavis,38015,Nave San Felice,\n",
    "8,OBRELLI GIOIELLERIA DAL 1929 S.R.L.,Via Roma,33,Lavis,38015,,\n",
    "9,MACELLERIE TROIER S.A.S. DI TROIER DARIO E C.,Via Roma,13,Lavis,38015,,\n",
    "10,NARDELLI TIZIANO,Piazza Manci,5,Lavis,38015,,esercizio commerciale\n",
    "```\n",
    "\n",
    "\n",
    "As expected, values are separated with commas.\n",
    "\n",
    "### Problem: wrong characters ??\n",
    "\n",
    "You can suddenly discover a problem in the first row of headers, in the column `Frazione/LocalitÃ`. It seems last character is wrong, in italian it should show accented like `à`. Is it truly a problem of the file ? Not really. Probably, the server is not telling Firefox which encoding is the correct one for the file. Firefox is not magical, and tries its best to show the CSV on the base of the info it has, which may be limited and / or even wrong. World is never like we would like it to be ...\n",
    "\n",
    "\n",
    "**✪ 2.12 EXERCISE**: download the CSV, and try opening it in Excel and / or LibreOffice Calc. Do you see a correct accented character? If not, try to set the encoding to 'Unicode (UTF-8)'  (in Calc is called 'Character set').\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "           \n",
    "**WARNING: CAREFUL IF YOU USE Excel!**\n",
    "     \n",
    "By clicking directly on  `File->Open in Excel`, probably Excel will try to guess on its own how to put the CSV in a table, and will make the mistake to place everything in a column. To avoid the problem, we have to tell Excel to show a panel to ask us how we want to open the CSV, by doing like so:\n",
    "\n",
    "* In old Excels, find `File-> Import`\n",
    "* In recent Excels, click on tab `Data` and then select `From text`. For further information, [see copytrans guide](https://www.copytrans.net/support/how-to-open-a-csv-file-in-excel/)\n",
    "</div>\n",
    "\n",
    "\n",
    "- **NOTE**: If the file is not available, in the folder where this notebook is you will find the same file renamed to `botteghe-storiche.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![import example in LibreOffice Calc](img/botteghe-import.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get a table like this. Notice how the `Frazione/Località` header displays with the right accent because we selected Character set: Unicode (UTF-8) which is the appropriate one for this dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![botteghe storiche table](img/botteghe-table.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Botteghe storiche in Python\n",
    "\n",
    "Now that we understood a couple of things about encoding, let's try to import the file in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we load in Python the first 5 entries with a csv DictReader and print them we should see something like this:\n",
    "\n",
    "```python\n",
    "OrderedDict([('Numero', '1'),\n",
    "              ('Insegna', 'BAZZANELLA RENATA'),\n",
    "              ('Indirizzo', 'Via del Lagorai'),\n",
    "              ('Civico', '30'),\n",
    "              ('Comune', 'Sover'),\n",
    "              ('Cap', '38068'),\n",
    "              ('Frazione/Località', 'Piscine di Sover'),\n",
    "              ('Note', 'generi misti, bar - ristorante')]),\n",
    "OrderedDict([('Numero', '2'),\n",
    "             ('Insegna', 'CONFEZIONI MONTIBELLER S.R.L.'),\n",
    "             ('Indirizzo', 'Corso Ausugum'),\n",
    "             ('Civico', '48'),\n",
    "             ('Comune', 'Borgo Valsugana'),\n",
    "             ('Cap', '38051'),\n",
    "             ('Frazione/Località', ''),\n",
    "             ('Note', 'esercizio commerciale')]),\n",
    "OrderedDict([('Numero', '3'),\n",
    "             ('Insegna', 'FOTOGRAFICA TRINTINAGLIA UMBERTO S.N.C.'),\n",
    "             ('Indirizzo', 'Largo Dordi'),\n",
    "             ('Civico', '8'),\n",
    "             ('Comune', 'Borgo Valsugana'),\n",
    "             ('Cap', '38051'),\n",
    "             ('Frazione/Località', ''),\n",
    "             ('Note', 'esercizio commerciale, attività artigianale')]),\n",
    "OrderedDict([('Numero', '4'),\n",
    "             ('Insegna', 'BAR SERAFINI DI MINATI RENZO'),\n",
    "             ('Indirizzo', ''),\n",
    "             ('Civico', '24'),\n",
    "             ('Comune', 'Grigno'),\n",
    "             ('Cap', '38055'),\n",
    "             ('Frazione/Località', 'Serafini'),\n",
    "             ('Note', 'esercizio commerciale')]),\n",
    "OrderedDict([('Numero', '6'),\n",
    "             ('Insegna', 'SEMBENINI GINO & FIGLI S.R.L.'),\n",
    "             ('Indirizzo', 'Via S. Francesco'),\n",
    "             ('Civico', '35'),\n",
    "             ('Comune', 'Riva del Garda'),\n",
    "             ('Cap', '38066'),\n",
    "             ('Frazione/Località', ''),\n",
    "             ('Note', '')])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to know which different categories of _bottega_ there are, and count them. Unfortunately, there is no specific field for _Categoria,_ so we will need to extract this information from other fields such as `Insegna` and `Note`. For example, this `Insegna` contains the category `BAR`, while the `Note` (_commercial enterprise_) is a bit too generic to be useful:\n",
    "\n",
    "```python\n",
    "    'Insegna': 'BAR SERAFINI DI MINATI RENZO',\n",
    "    'Note': 'esercizio commerciale',\n",
    "```\n",
    "\n",
    "while this other `Insegna` contains just the owner name and  `Note` holds both the categories `bar` and `ristorante`:\n",
    "\n",
    "```python\n",
    "    'Insegna': 'BAZZANELLA RENATA',\n",
    "    'Note': 'generi misti, bar - ristorante',\n",
    "```\n",
    "\n",
    "As you see, data is non uniform: \n",
    "\n",
    "* sometimes the category is in the `Insegna`\n",
    "* sometimes is in the `Note`\n",
    "* sometimes is in both\n",
    "* sometimes is lowercase\n",
    "* sometimes is uppercase\n",
    "* sometimes is single\n",
    "* sometimes is multiple (`bar - ristorante`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to extract all categories we can find, and rank them according their frequency, from most frequent to least frequent.\n",
    "\n",
    "To do so, you need to\n",
    "\n",
    "- count all words you can find in both `Insegna` and `Note` fields, and sort them. Note you need to normalize the uppercase. \n",
    "\n",
    "- consider a category relevant if it is present at least 11 times in the dataset.\n",
    "\n",
    "- filter non relevant words: some words like prepositions, type of company (`'S.N.C'`, `S.R.L.`, ..), etc will appear a lot, and will need to be ignored. To detect them, you are given a list called `stopwords`.\n",
    "\n",
    "**NOTE**: the rules above do not actually extract all the categories, for the sake of the exercise we only keep the most frequent ones. \n",
    "\n",
    "To know how to proceed, read the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Botteghe storiche - rank_categories\n",
    "\n",
    "Load the file with `csv.DictReader` and while you are loading it, calculate the words as described above. Afterwards, return a list of words with their frequencies.\n",
    "\n",
    "Do **not** load the whole file into memory, just process one dictionary at a time and update statistics accordingly.\n",
    "\n",
    "Expected output: \n",
    "\n",
    "```python\n",
    "[('BAR', 191),\n",
    " ('RISTORANTE', 150),\n",
    " ('HOTEL', 67),\n",
    " ('ALBERGO', 64),\n",
    " ('MACELLERIA', 27),\n",
    " ('PANIFICIO', 22),\n",
    " ('CALZATURE', 21),\n",
    " ('FARMACIA', 21),\n",
    " ('ALIMENTARI', 20),\n",
    " ('PIZZERIA', 16),\n",
    " ('SPORT', 16),\n",
    " ('TABACCHI', 12),\n",
    " ('FERRAMENTA', 12),\n",
    " ('BAZAR', 11)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BAR', 191),\n",
       " ('RISTORANTE', 150),\n",
       " ('HOTEL', 67),\n",
       " ('ALBERGO', 64),\n",
       " ('MACELLERIA', 27),\n",
       " ('PANIFICIO', 22),\n",
       " ('CALZATURE', 21),\n",
       " ('FARMACIA', 21),\n",
       " ('ALIMENTARI', 20),\n",
       " ('SPORT', 16),\n",
       " ('PIZZERIA', 16),\n",
       " ('TABACCHI', 12),\n",
       " ('FERRAMENTA', 12),\n",
       " ('BAZAR', 11)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank_categories(stopwords):\n",
    "    #jupman-raise\n",
    "    ret = {}\n",
    "    import csv\n",
    "    with open('botteghe.csv', newline='',  encoding='utf-8',) as csvfile:\n",
    "        reader = csv.DictReader(csvfile,  delimiter=',')\n",
    "        for d in reader:\n",
    "            words = d['Insegna'].split(\" \") + d['Note'].upper().split(\" \") \n",
    "            for word in words:\n",
    "                if word in ret and not word in stopwords:\n",
    "                    ret[word] += 1\n",
    "                else:\n",
    "                    ret[word] = 1\n",
    "    return sorted([(key, val) for key,val in ret.items() if val > 10], key=lambda c: c[1], reverse=True)\n",
    "    #/jupman-raise\n",
    "\n",
    "stopwords = ['',\n",
    "             'S.N.C.', 'SNC','S.A.S.', 'S.R.L.', 'S.C.A.R.L.', 'SCARL','S.A.S', 'COMMERCIALE','FAMIGLIA','COOPERATIVA',\n",
    "             '-', '&', 'C.', 'ESERCIZIO',\n",
    "             'IL', 'DE', 'DI','A', 'DA', 'E', 'LA', 'AL',  'DEL', 'ALLA', ]\n",
    "categories = rank_categories(stopwords)\n",
    "\n",
    "categories  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Botteghe storiche - enrich\n",
    "\n",
    "Once you found the categories, implement function `enrich`, which takes the db and previously computed categories, and WRITES a NEW file `botteghe-enriched.csv` where the rows are enriched with a new field `Categorie`, which holds a list of the categories a particular _bottega_ belongs to. \n",
    "\n",
    "- Write the new file with a `DictWriter`, see [documentation](https://docs.python.org/3/library/csv.html#csv.DictWriter)\n",
    "\n",
    "The new file should contain rows like this (showing only first 5):\n",
    "\n",
    "```bash\n",
    "OrderedDict([   ('Numero', '1'),\n",
    "                ('Insegna', 'BAZZANELLA RENATA'),\n",
    "                ('Indirizzo', 'Via del Lagorai'),\n",
    "                ('Civico', '30'),\n",
    "                ('Comune', 'Sover'),\n",
    "                ('Cap', '38068'),\n",
    "                ('Frazione/Località', 'Piscine di Sover'),\n",
    "                ('Note', 'generi misti, bar - ristorante'),\n",
    "                ('Categorie', \"['BAR', 'RISTORANTE']\")])\n",
    "OrderedDict([   ('Numero', '2'),\n",
    "                ('Insegna', 'CONFEZIONI MONTIBELLER S.R.L.'),\n",
    "                ('Indirizzo', 'Corso Ausugum'),\n",
    "                ('Civico', '48'),\n",
    "                ('Comune', 'Borgo Valsugana'),\n",
    "                ('Cap', '38051'),\n",
    "                ('Frazione/Località', ''),\n",
    "                ('Note', 'esercizio commerciale'),\n",
    "                ('Categorie', '[]')])\n",
    "OrderedDict([   ('Numero', '3'),\n",
    "                ('Insegna', 'FOTOGRAFICA TRINTINAGLIA UMBERTO S.N.C.'),\n",
    "                ('Indirizzo', 'Largo Dordi'),\n",
    "                ('Civico', '8'),\n",
    "                ('Comune', 'Borgo Valsugana'),\n",
    "                ('Cap', '38051'),\n",
    "                ('Frazione/Località', ''),\n",
    "                ('Note', 'esercizio commerciale, attività artigianale'),\n",
    "                ('Categorie', '[]')])\n",
    "OrderedDict([   ('Numero', '4'),\n",
    "                ('Insegna', 'BAR SERAFINI DI MINATI RENZO'),\n",
    "                ('Indirizzo', ''),\n",
    "                ('Civico', '24'),\n",
    "                ('Comune', 'Grigno'),\n",
    "                ('Cap', '38055'),\n",
    "                ('Frazione/Località', 'Serafini'),\n",
    "                ('Note', 'esercizio commerciale'),\n",
    "                ('Categorie', \"['BAR']\")])\n",
    "OrderedDict([   ('Numero', '6'),\n",
    "                ('Insegna', 'SEMBENINI GINO & FIGLI S.R.L.'),\n",
    "                ('Indirizzo', 'Via S. Francesco'),\n",
    "                ('Civico', '35'),\n",
    "                ('Comune', 'Riva del Garda'),\n",
    "                ('Cap', '38066'),\n",
    "                ('Frazione/Località', ''),\n",
    "                ('Note', ''),\n",
    "                ('Categorie', '[]')])\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def enrich(categories):\n",
    "    #jupman-raise\n",
    "    ret = []\n",
    "\n",
    "    \n",
    "    fieldnames = []\n",
    "    # read headers \n",
    "    with open('botteghe.csv', newline='',  encoding='utf-8') as csvfile_in:\n",
    "        reader = csv.DictReader(csvfile_in,  delimiter=',')\n",
    "        d1 = next(reader)\n",
    "        fieldnames = list(d1.keys())  # otherwise we cannot append\n",
    "    \n",
    "    fieldnames.append('Categorie')\n",
    "    \n",
    "    with open('botteghe-enriched-solution.csv', 'w', newline='', encoding='utf-8') as csvfile_out:\n",
    "    \n",
    "        writer = csv.DictWriter(csvfile_out, fieldnames=fieldnames)            \n",
    "        writer.writeheader()\n",
    "    \n",
    "        with open('botteghe.csv', newline='',  encoding='utf-8',) as csvfile_in:\n",
    "            reader = csv.DictReader(csvfile_in,  delimiter=',')\n",
    "            for d in reader:\n",
    "\n",
    "                new_d = {key:val for key,val in d.items()}\n",
    "                new_d['Categorie'] = []\n",
    "                for cat in categories:\n",
    "                    if cat[0] in d['Insegna'].upper() or cat[0] in d['Note'].upper():\n",
    "                        new_d['Categorie'].append(cat[0])\n",
    "                writer.writerow(new_d)\n",
    "    \n",
    "    #/jupman-raise\n",
    "\n",
    "enrich(rank_categories(stopwords))                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Cap': '38068',\n",
      "    'Categorie': \"['BAR', 'RISTORANTE']\",\n",
      "    'Civico': '30',\n",
      "    'Comune': 'Sover',\n",
      "    'Frazione/Località': 'Piscine di Sover',\n",
      "    'Indirizzo': 'Via del Lagorai',\n",
      "    'Insegna': 'BAZZANELLA RENATA',\n",
      "    'Note': 'generi misti, bar - ristorante',\n",
      "    'Numero': '1'}\n",
      "{   'Cap': '38051',\n",
      "    'Categorie': '[]',\n",
      "    'Civico': '48',\n",
      "    'Comune': 'Borgo Valsugana',\n",
      "    'Frazione/Località': '',\n",
      "    'Indirizzo': 'Corso Ausugum',\n",
      "    'Insegna': 'CONFEZIONI MONTIBELLER S.R.L.',\n",
      "    'Note': 'esercizio commerciale',\n",
      "    'Numero': '2'}\n",
      "{   'Cap': '38051',\n",
      "    'Categorie': '[]',\n",
      "    'Civico': '8',\n",
      "    'Comune': 'Borgo Valsugana',\n",
      "    'Frazione/Località': '',\n",
      "    'Indirizzo': 'Largo Dordi',\n",
      "    'Insegna': 'FOTOGRAFICA TRINTINAGLIA UMBERTO S.N.C.',\n",
      "    'Note': 'esercizio commerciale, attività artigianale',\n",
      "    'Numero': '3'}\n",
      "{   'Cap': '38055',\n",
      "    'Categorie': \"['BAR']\",\n",
      "    'Civico': '24',\n",
      "    'Comune': 'Grigno',\n",
      "    'Frazione/Località': 'Serafini',\n",
      "    'Indirizzo': '',\n",
      "    'Insegna': 'BAR SERAFINI DI MINATI RENZO',\n",
      "    'Note': 'esercizio commerciale',\n",
      "    'Numero': '4'}\n",
      "{   'Cap': '38066',\n",
      "    'Categorie': '[]',\n",
      "    'Civico': '35',\n",
      "    'Comune': 'Riva del Garda',\n",
      "    'Frazione/Località': '',\n",
      "    'Indirizzo': 'Via S. Francesco',\n",
      "    'Insegna': 'SEMBENINI GINO & FIGLI S.R.L.',\n",
      "    'Note': '',\n",
      "    'Numero': '6'}\n"
     ]
    }
   ],
   "source": [
    "# let's see if we created the file we wanted \n",
    "# (using botteghe-enriched-solution.csv to avoid polluting your file)\n",
    "\n",
    "with open('botteghe-enriched-solution.csv', newline='',  encoding='utf-8',) as csvfile_in:\n",
    "    reader = csv.DictReader(csvfile_in,  delimiter=',')\n",
    "    # better to pretty print the OrderedDicts, otherwise we get unreadable output   \n",
    "    # for documentation see https://docs.python.org/3/library/pprint.html\n",
    "    import pprint\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    for i in range(5):\n",
    "        d = next(reader)\n",
    "        pp.pprint(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JSON files\n",
    "\n",
    "JSON is a more elaborated format, widely used in the world of web applications.\n",
    "\n",
    "A json is simply a text file, structured as _a tree._ Let's see an example, extracted from the data Bike sharing stations of Lavis municipality as found on  dati.trentino : \n",
    "\n",
    "- Data source: [dati.trentino.it](https://dati.trentino.it/dataset/stazioni-bike-sharing-emotion-trentino) - Trasport Service of the Autonomous Province of Trento\n",
    "- License: [CC-BY 4.0](http://creativecommons.org/licenses/by/4.0/deed.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File [bike-sharing-lavis.json](bike-sharing-lavis.json):\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Grazioli\",\n",
    "    \"address\": \"Piazza Grazioli - Lavis\",\n",
    "    \"id\": \"Grazioli - Lavis\",\n",
    "    \"bikes\": 3,\n",
    "    \"slots\": 7,\n",
    "    \"totalSlots\": 10,\n",
    "    \"position\": [\n",
    "      46.139732902099794,\n",
    "      11.111516155225331\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Pressano\",\n",
    "    \"address\": \"Piazza della Croce - Pressano\",\n",
    "    \"id\": \"Pressano - Lavis\",\n",
    "    \"bikes\": 2,\n",
    "    \"slots\": 5,\n",
    "    \"totalSlots\": 7,\n",
    "    \"position\": [\n",
    "      46.15368174037716,\n",
    "      11.106601229430453\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Stazione RFI\",\n",
    "    \"address\": \"Via Stazione - Lavis\",\n",
    "    \"id\": \"Stazione RFI - Lavis\",\n",
    "    \"bikes\": 4,\n",
    "    \"slots\": 6,\n",
    "    \"totalSlots\": 10,\n",
    "    \"position\": [\n",
    "      46.148180371138814,\n",
    "      11.096753997622727\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the json format is very similar to data structures we already have in Python, such as strings, integer numbers, floats, lists and dictionaries. The only difference are the json `null` fields which become `None` in Python. So the conversion to Python is almost always easy and painless, to perform it you can use the native Python module called `json` by calling the function `json.load`, which interprets the json text file and converts it to a Python data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Grazioli', 'position': [46.139732902099794, 11.111516155225331], 'id': 'Grazioli - Lavis', 'slots': 7, 'totalSlots': 10, 'bikes': 3, 'address': 'Piazza Grazioli - Lavis'}, {'name': 'Pressano', 'position': [46.15368174037716, 11.106601229430453], 'id': 'Pressano - Lavis', 'slots': 5, 'totalSlots': 7, 'bikes': 2, 'address': 'Piazza della Croce - Pressano'}, {'name': 'Stazione RFI', 'position': [46.148180371138814, 11.096753997622727], 'id': 'Stazione RFI - Lavis', 'slots': 6, 'totalSlots': 10, 'bikes': 4, 'address': 'Via Stazione - Lavis'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('bike-sharing-lavis.json',  encoding='utf-8') as f:\n",
    "    python_content = json.load(f)\n",
    "    \n",
    "print(python_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that what we've just read with the function `json.load` is not simple text anymore, but Python objects. For this json, the most external object is a list (note the square brackets at the file beginning and end). We can check using `type` on `python_content`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(python_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the JSON closely, you will see it is a list of dictionaries. Thus, to access the first dictionary (that is, the one at zero-th index), we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': 'Piazza Grazioli - Lavis',\n",
       " 'bikes': 3,\n",
       " 'id': 'Grazioli - Lavis',\n",
       " 'name': 'Grazioli',\n",
       " 'position': [46.139732902099794, 11.111516155225331],\n",
       " 'slots': 7,\n",
       " 'totalSlots': 10}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it's the station in  Piazza Grazioli. To get the exact name, we will access the `'address'` key in the first dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Piazza Grazioli - Lavis'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_content[0]['address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the position, we will use the corresponding key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.139732902099794, 11.111516155225331]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_content[0]['position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the position is a list itself. In JSON we can have arbitrarily branched trees, without necessarily a regular structure (althouth when we're generating a json it certainly helps maintaining a regualar data scheme)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSONL\n",
    "\n",
    "There is a particular JSON file type which is called [JSONL](http://jsonlines.org/) (note the _L_ at the end), which is a text file containing a sequence of lines, each representing a valid json object.\n",
    "\n",
    "Let's have a look at the file [employees.jsonl](employees.jsonl):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"name\": \"Mario\", \"surname\":\"Rossi\"}\n",
    "{\"name\": \"Paolo\", \"surname\":\"Bianchi\"}\n",
    "{\"name\": \"Luca\", \"surname\":\"Verdi\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read it, we can open the file, separating the text lines and then interpret each of them as a single JSON object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object  0\n",
      "{'name': 'Mario', 'surname': 'Rossi'}\n",
      "Object  1\n",
      "{'name': 'Paolo', 'surname': 'Bianchi'}\n",
      "Object  2\n",
      "{'name': 'Luca', 'surname': 'Verdi'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./employees.jsonl', encoding='utf-8',) as f:\n",
    "    json_texts_list = list(f)       #  converts file text lines into a Python list\n",
    "    \n",
    "\n",
    "# in this case we will have a python content for each row of the original file\n",
    "\n",
    "i = 0\n",
    "for json_text in json_texts_list:\n",
    "    python_content = json.loads(json_text)   # converts json text to a python object\n",
    "    print('Object ', i)\n",
    "    print(python_content)\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
